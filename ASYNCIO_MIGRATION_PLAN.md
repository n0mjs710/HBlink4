# asyncio Migration Plan - Multi-Solution Analysis

**Branch:** feature/asyncio-migration  
**Base:** v1.6.0 (main branch)  
**Target:** Python 3.11+ asyncio implementation  
**Status:** In Progress

---

## Risk Classification & Strategy

### LOW RISK (Direct 1:1 mapping, no alternatives needed)
- ‚úÖ Import changes (Twisted ‚Üí asyncio)
- ‚úÖ Protocol base class change (DatagramProtocol ‚Üí asyncio.DatagramProtocol)
- ‚úÖ Method renames (datagramReceived ‚Üí datagram_received, startProtocol ‚Üí connection_made)

### MODERATE RISK (Requires multi-solution analysis)
1. **Signal Handlers** - Different semantics between Twisted and asyncio
2. **LoopingCall ‚Üí Periodic Tasks** - Task lifecycle and cancellation
3. **Main Event Loop Setup** - UDP endpoint creation and lifecycle

### HIGH RISK (Complex interactions, requires careful analysis)
- None identified (all risks are moderate due to simple single-threaded UDP architecture)

---

## Checkpoint Strategy

**Checkpoint 1:** Import changes + protocol base (easy rollback)  
**Checkpoint 2:** Method renames (syntactic only)  
**Checkpoint 3:** Signal handlers (independently testable)  
**Checkpoint 4:** LoopingCall conversion (isolated to timing tasks)  
**Checkpoint 5:** Main event loop (final integration)  

Each checkpoint will be tested before proceeding.

---

## Moderate Risk Item #1: Signal Handlers

### Background
Twisted uses standard Python `signal.signal()` for signal handling. asyncio provides `loop.add_signal_handler()` which has different semantics and limitations.

### Current Implementation (Twisted)
```python
def signal_handler(signum, frame):
    """Handle shutdown signals by cleaning up and stopping reactor"""
    signame = signal.Signals(signum).name
    LOGGER.info(f"Received shutdown signal {signame}")
    protocol.cleanup()
    reactor.stop()

signal.signal(signal.SIGINT, signal_handler)
signal.signal(signal.SIGTERM, signal_handler)
```

### Challenges
1. **Signature difference:** asyncio handlers don't receive `signum` or `frame` arguments
2. **Loop access:** Need reference to running event loop
3. **Cleanup ordering:** Must ensure cleanup happens before loop stops
4. **Unix-only:** `loop.add_signal_handler()` only works on Unix (not Windows)

---

### Solution 1A: asyncio Native Signal Handlers (Recommended for Unix)

**Approach:** Use asyncio's built-in signal handling (Unix-only)

```python
async def async_main():
    loop = asyncio.get_running_loop()
    
    # Create protocol and transports
    protocol = HBProtocol()
    transport_v4, _ = await loop.create_datagram_endpoint(
        lambda: protocol,
        local_addr=(bind_ipv4, port_ipv4)
    )
    
    # Define signal handler closure
    def handle_shutdown(signum):
        signame = signal.Signals(signum).name
        LOGGER.info(f"Received shutdown signal {signame}")
        protocol.cleanup()
        loop.stop()
    
    # Register signal handlers (Unix-only)
    loop.add_signal_handler(signal.SIGINT, lambda: handle_shutdown(signal.SIGINT))
    loop.add_signal_handler(signal.SIGTERM, lambda: handle_shutdown(signal.SIGTERM))
    
    # Run forever
    try:
        await asyncio.Event().wait()
    except asyncio.CancelledError:
        pass

def main():
    load_config()
    setup_logging()
    asyncio.run(async_main())
```

**Pros:**
- ‚úÖ Native asyncio pattern
- ‚úÖ Clean integration with event loop
- ‚úÖ Proper async context handling
- ‚úÖ Most efficient (no signal ‚Üí asyncio bridge overhead)

**Cons:**
- ‚ùå Unix-only (not portable to Windows)
- ‚ùå Must have running event loop (can't use during startup)
- ‚ùå Lambda closures slightly less readable

**Risk Assessment:** LOW  
**Compatibility:** Unix-only (acceptable - DMR servers run on Linux)

---

### Solution 1B: Hybrid Signal + asyncio (Cross-platform)

**Approach:** Use standard `signal.signal()` but communicate via asyncio Event

```python
shutdown_event = None

def signal_handler(signum, frame):
    """Handle shutdown signals (called from signal context)"""
    signame = signal.Signals(signum).name
    LOGGER.info(f"Received shutdown signal {signame}")
    if shutdown_event:
        shutdown_event.set()  # Thread-safe signal to asyncio

async def async_main():
    global shutdown_event
    loop = asyncio.get_running_loop()
    shutdown_event = asyncio.Event()
    
    # Create protocol
    protocol = HBProtocol()
    transport_v4, _ = await loop.create_datagram_endpoint(
        lambda: protocol,
        local_addr=(bind_ipv4, port_ipv4)
    )
    
    # Wait for shutdown signal
    await shutdown_event.wait()
    
    # Cleanup
    protocol.cleanup()

def main():
    load_config()
    setup_logging()
    
    # Register signal handlers (works on all platforms)
    signal.signal(signal.SIGINT, signal_handler)
    signal.signal(signal.SIGTERM, signal_handler)
    
    try:
        asyncio.run(async_main())
    except KeyboardInterrupt:
        LOGGER.info("Received KeyboardInterrupt")
```

**Pros:**
- ‚úÖ Cross-platform (Windows + Unix)
- ‚úÖ Familiar signal.signal() pattern
- ‚úÖ Clean separation of concerns
- ‚úÖ asyncio.Event() is thread-safe for signaling

**Cons:**
- ‚ùå Global variable required
- ‚ùå Slightly more complex flow
- ‚ùå Extra synchronization overhead (negligible)

**Risk Assessment:** LOW  
**Compatibility:** Cross-platform

---

### Solution 1C: asyncio.run() with Cancellation

**Approach:** Let asyncio.run() handle KeyboardInterrupt naturally

```python
async def async_main():
    loop = asyncio.get_running_loop()
    
    protocol = HBProtocol()
    transport_v4, _ = await loop.create_datagram_endpoint(
        lambda: protocol,
        local_addr=(bind_ipv4, port_ipv4)
    )
    
    # Setup SIGTERM handler only (SIGINT handled by asyncio.run)
    if hasattr(signal, 'SIGTERM'):  # Unix-only
        def handle_sigterm():
            LOGGER.info("Received SIGTERM")
            raise KeyboardInterrupt  # Reuse cleanup path
        
        loop.add_signal_handler(signal.SIGTERM, handle_sigterm)
    
    try:
        # Run forever until interrupted
        await asyncio.Event().wait()
    finally:
        # Cleanup happens here (always runs)
        LOGGER.info("Starting graceful shutdown...")
        protocol.cleanup()

def main():
    load_config()
    setup_logging()
    
    try:
        asyncio.run(async_main())
    except KeyboardInterrupt:
        LOGGER.info("Shutdown complete")
```

**Pros:**
- ‚úÖ Simplest code (leverages asyncio.run() cleanup)
- ‚úÖ try/finally ensures cleanup always runs
- ‚úÖ Natural KeyboardInterrupt handling
- ‚úÖ Minimal code changes

**Cons:**
- ‚ùå SIGTERM requires Unix-specific handler
- ‚ùå Mixing asyncio and signal handlers
- ‚ùå Less explicit control flow

**Risk Assessment:** LOW  
**Compatibility:** Partial (SIGINT cross-platform, SIGTERM Unix-only)

---

### Solution 1: FINAL RECOMMENDATION

**Selected:** **Solution 1A (asyncio Native)** with fallback documentation

**Rationale:**
1. HBlink4 targets Linux servers exclusively (no Windows support needed)
2. Most Pythonic asyncio pattern
3. Best performance (no signal bridging)
4. Clearest code structure
5. Most maintainable long-term

**Implementation:**
- Use Solution 1A as primary
- Document Unix requirement clearly
- If Windows support ever needed, migrate to Solution 1B

**Confidence Level:** HIGH (all 3 solutions viable, 1A is cleanest for our use case)

---

## Moderate Risk Item #2: LoopingCall ‚Üí Periodic Tasks

### Background
Twisted's `LoopingCall` provides periodic task execution with start/stop lifecycle. asyncio has no direct equivalent - must implement using tasks + sleep loops.

### Current Implementation (Twisted)
```python
self._timeout_task = LoopingCall(self._check_repeater_timeouts)
self._timeout_task.start(30)  # Every 30 seconds

self._stream_timeout_task = LoopingCall(self._check_stream_timeouts)
self._stream_timeout_task.start(1.0)  # Every 1 second

# In stopProtocol():
if self._timeout_task and self._timeout_task.running:
    self._timeout_task.stop()
```

### Challenges
1. **No built-in equivalent:** Must create while loop + sleep pattern
2. **Cancellation:** Must handle task cancellation gracefully
3. **Exception handling:** Exceptions must not crash the task
4. **Timing drift:** Need to handle timing precision
5. **Lifecycle:** Start in connection_made(), stop in connection_lost()

---

### Solution 2A: Simple While Loop with Sleep (Most Straightforward)

**Approach:** Direct translation with asyncio.sleep()

```python
class HBProtocol(asyncio.DatagramProtocol):
    def __init__(self):
        super().__init__()
        self._timeout_task = None
        self._stream_timeout_task = None
        self._user_cache_cleanup_task = None
        self._shutdown = False
    
    async def _repeater_timeout_loop(self):
        """Periodic repeater timeout checker (every 30s)"""
        try:
            while not self._shutdown:
                await asyncio.sleep(30)
                if not self._shutdown:  # Double-check after sleep
                    try:
                        self._check_repeater_timeouts()
                    except Exception as e:
                        LOGGER.error(f"Error in repeater timeout check: {e}")
        except asyncio.CancelledError:
            LOGGER.debug("Repeater timeout task cancelled")
            raise
    
    async def _stream_timeout_loop(self):
        """Periodic stream timeout checker (every 1s)"""
        try:
            while not self._shutdown:
                await asyncio.sleep(1.0)
                if not self._shutdown:
                    try:
                        self._check_stream_timeouts()
                    except Exception as e:
                        LOGGER.error(f"Error in stream timeout check: {e}")
        except asyncio.CancelledError:
            LOGGER.debug("Stream timeout task cancelled")
            raise
    
    async def _user_cache_cleanup_loop(self):
        """Periodic user cache cleanup (every 60s)"""
        try:
            while not self._shutdown:
                await asyncio.sleep(60)
                if not self._shutdown:
                    try:
                        self._cleanup_user_cache()
                    except Exception as e:
                        LOGGER.error(f"Error in user cache cleanup: {e}")
        except asyncio.CancelledError:
            LOGGER.debug("User cache cleanup task cancelled")
            raise
    
    def connection_made(self, transport):
        """Called when transport connects"""
        self.transport = transport
        self._shutdown = False
        
        # Start periodic tasks
        self._timeout_task = asyncio.create_task(self._repeater_timeout_loop())
        self._stream_timeout_task = asyncio.create_task(self._stream_timeout_loop())
        self._user_cache_cleanup_task = asyncio.create_task(self._user_cache_cleanup_loop())
    
    def connection_lost(self, exc):
        """Called when transport disconnects"""
        self._shutdown = True
        
        # Cancel tasks
        if self._timeout_task:
            self._timeout_task.cancel()
        if self._stream_timeout_task:
            self._stream_timeout_task.cancel()
        if self._user_cache_cleanup_task:
            self._user_cache_cleanup_task.cancel()
```

**Pros:**
- ‚úÖ Simple, readable code
- ‚úÖ Direct translation from LoopingCall
- ‚úÖ Graceful cancellation handling
- ‚úÖ Per-task exception handling (one task crash doesn't affect others)
- ‚úÖ Explicit shutdown flag prevents race conditions

**Cons:**
- ‚ùå Boilerplate duplication (3 similar loop functions)
- ‚ùå _shutdown flag adds state
- ‚ùå Double-check pattern slightly verbose

**Risk Assessment:** LOW  
**Maintainability:** Good (clear and explicit)

---

### Solution 2B: Generic Periodic Task Helper (DRY Principle)

**Approach:** Create reusable periodic task wrapper to eliminate duplication

```python
class HBProtocol(asyncio.DatagramProtocol):
    def __init__(self):
        super().__init__()
        self._tasks = []
    
    async def _run_periodic(self, interval: float, func, name: str):
        """
        Generic periodic task runner.
        
        Args:
            interval: Seconds between executions
            func: Synchronous function to call
            name: Task name for logging
        """
        try:
            while True:
                await asyncio.sleep(interval)
                try:
                    func()
                except Exception as e:
                    LOGGER.error(f"Error in {name}: {e}", exc_info=True)
        except asyncio.CancelledError:
            LOGGER.debug(f"{name} task cancelled")
            raise
    
    def connection_made(self, transport):
        """Called when transport connects"""
        self.transport = transport
        
        # Start periodic tasks using helper
        self._tasks = [
            asyncio.create_task(self._run_periodic(30, self._check_repeater_timeouts, "repeater timeout checker")),
            asyncio.create_task(self._run_periodic(1.0, self._check_stream_timeouts, "stream timeout checker")),
            asyncio.create_task(self._run_periodic(60, self._cleanup_user_cache, "user cache cleanup"))
        ]
    
    def connection_lost(self, exc):
        """Called when transport disconnects"""
        # Cancel all tasks
        for task in self._tasks:
            task.cancel()
        self._tasks.clear()
```

**Pros:**
- ‚úÖ DRY - No code duplication
- ‚úÖ Reusable pattern for future tasks
- ‚úÖ Cleaner connection_made() code
- ‚úÖ Easier to add new periodic tasks
- ‚úÖ Centralized exception handling

**Cons:**
- ‚ùå Extra abstraction layer
- ‚ùå Slightly less explicit (function passed as parameter)
- ‚ùå Loses individual task references (if needed for other operations)

**Risk Assessment:** LOW  
**Maintainability:** Excellent (DRY, extensible)

---

### Solution 2C: Immediate First Run + Timing Precision

**Approach:** Handle timing drift and immediate execution

```python
class HBProtocol(asyncio.DatagramProtocol):
    def __init__(self):
        super().__init__()
        self._tasks = {}
    
    async def _repeater_timeout_loop(self):
        """Repeater timeout checker with precise timing"""
        interval = 30
        try:
            # Run immediately on start
            self._check_repeater_timeouts()
            
            # Then run periodically with drift compensation
            next_run = asyncio.get_event_loop().time() + interval
            
            while True:
                now = asyncio.get_event_loop().time()
                sleep_time = max(0, next_run - now)
                await asyncio.sleep(sleep_time)
                
                try:
                    self._check_repeater_timeouts()
                except Exception as e:
                    LOGGER.error(f"Error in repeater timeout check: {e}")
                
                # Schedule next run (compensates for execution time)
                next_run += interval
                
        except asyncio.CancelledError:
            LOGGER.debug("Repeater timeout task cancelled")
            raise
    
    async def _stream_timeout_loop(self):
        """Stream timeout checker with precise 1-second timing"""
        interval = 1.0
        try:
            # Run immediately
            self._check_stream_timeouts()
            
            next_run = asyncio.get_event_loop().time() + interval
            
            while True:
                now = asyncio.get_event_loop().time()
                sleep_time = max(0, next_run - now)
                await asyncio.sleep(sleep_time)
                
                try:
                    self._check_stream_timeouts()
                except Exception as e:
                    LOGGER.error(f"Error in stream timeout check: {e}")
                
                next_run += interval
                
        except asyncio.CancelledError:
            LOGGER.debug("Stream timeout task cancelled")
            raise
    
    # ... similar for _user_cache_cleanup_loop
    
    def connection_made(self, transport):
        """Called when transport connects"""
        self.transport = transport
        
        # Start tasks
        self._tasks['repeater_timeout'] = asyncio.create_task(self._repeater_timeout_loop())
        self._tasks['stream_timeout'] = asyncio.create_task(self._stream_timeout_loop())
        self._tasks['user_cache'] = asyncio.create_task(self._user_cache_cleanup_loop())
    
    def connection_lost(self, exc):
        """Called when transport disconnects"""
        for name, task in self._tasks.items():
            task.cancel()
        self._tasks.clear()
```

**Pros:**
- ‚úÖ Immediate first execution (no 30s wait on startup)
- ‚úÖ Precise timing (compensates for execution drift)
- ‚úÖ Named tasks in dict (easier debugging)
- ‚úÖ More accurate long-term timing

**Cons:**
- ‚ùå More complex code
- ‚ùå Overkill for DMR (timing precision not critical)
- ‚ùå More verbose

**Risk Assessment:** LOW  
**Maintainability:** Fair (complexity vs benefit trade-off)

---

### Solution 2: FINAL RECOMMENDATION

**Selected:** **Solution 2B (Generic Helper)** 

**Rationale:**
1. **DRY principle:** Eliminates duplication across 3 tasks
2. **Extensibility:** Easy to add more periodic tasks in future
3. **Maintainability:** Single helper function to maintain
4. **Simplicity:** Cleaner than Solution 2A, simpler than Solution 2C
5. **Timing:** Simple sleep() is sufficient for DMR (not latency-critical)

**Why not 2C:**
- Timing precision not needed (30s ¬±1s doesn't matter for repeater timeouts)
- Stream timeout checker runs every 1s anyway (sub-second precision not required)
- Extra complexity not justified

**Why not 2A:**
- Code duplication maintenance burden
- Harder to ensure consistent error handling across all tasks

**Confidence Level:** HIGH (2B is clearly superior for maintainability)

---

## Moderate Risk Item #3: Main Event Loop Setup

### Background
Twisted uses `reactor.listenUDP()` for UDP sockets. asyncio uses `loop.create_datagram_endpoint()` with different patterns for IPv4/IPv6 dual-stack handling.

### Current Implementation (Twisted)
```python
def main():
    # ... config loading ...
    
    protocol = HBProtocol()
    
    # IPv4 listener
    if bind_ipv4:
        listener = reactor.listenUDP(port_ipv4, protocol, interface=bind_ipv4)
        LOGGER.info(f'‚úì HBlink4 listening on {bind_ipv4}:{port_ipv4} (UDP, IPv4)')
    
    # IPv6 listener (separate protocol instance)
    if bind_ipv6 and not disable_ipv6:
        protocol_v6 = HBProtocol()
        listener = reactor.listenUDP(port_ipv6, protocol_v6, interface=bind_ipv6)
        LOGGER.info(f'‚úì HBlink4 listening on [{bind_ipv6}]:{port_ipv6} (UDP, IPv6)')
    
    # Signal handlers
    signal.signal(signal.SIGINT, signal_handler)
    signal.signal(signal.SIGTERM, signal_handler)
    
    reactor.run()
```

### Challenges
1. **Multiple protocol instances:** IPv4 and IPv6 each need their own protocol
2. **Async endpoint creation:** create_datagram_endpoint() is async
3. **Error handling:** Must handle bind failures gracefully
4. **Port conflicts:** Dual-stack systems may conflict on same port
5. **Shutdown coordination:** Must cleanup both transports

---

### Solution 3A: Sequential Endpoint Creation (Explicit Control)

**Approach:** Create endpoints sequentially with explicit error handling

```python
async def async_main():
    """Main async entry point"""
    loop = asyncio.get_running_loop()
    
    # Load config
    bind_ipv4 = CONFIG.get('global', {}).get('bind_ipv4', '0.0.0.0')
    bind_ipv6 = CONFIG.get('global', {}).get('bind_ipv6', '::')
    port_ipv4 = CONFIG.get('global', {}).get('port_ipv4', 62031)
    port_ipv6 = CONFIG.get('global', {}).get('port_ipv6', 62031)
    disable_ipv6 = CONFIG.get('global', {}).get('disable_ipv6', False)
    
    transports = []
    protocols = []
    
    # Create IPv4 endpoint
    if bind_ipv4:
        try:
            protocol_v4 = HBProtocol()
            transport_v4, _ = await loop.create_datagram_endpoint(
                lambda: protocol_v4,
                local_addr=(bind_ipv4, port_ipv4)
            )
            transports.append(transport_v4)
            protocols.append(protocol_v4)
            LOGGER.info(f'‚úì HBlink4 listening on {bind_ipv4}:{port_ipv4} (UDP, IPv4)')
        except Exception as e:
            LOGGER.error(f'‚úó Failed to bind IPv4 to {bind_ipv4}:{port_ipv4}: {e}')
            if bind_ipv4 == '0.0.0.0':
                # Critical failure on wildcard bind
                sys.exit(1)
    
    # Create IPv6 endpoint
    if bind_ipv6 and not disable_ipv6:
        try:
            protocol_v6 = HBProtocol()
            transport_v6, _ = await loop.create_datagram_endpoint(
                lambda: protocol_v6,
                local_addr=(bind_ipv6, port_ipv6)
            )
            transports.append(transport_v6)
            protocols.append(protocol_v6)
            LOGGER.info(f'‚úì HBlink4 listening on [{bind_ipv6}]:{port_ipv6} (UDP, IPv6)')
        except OSError as e:
            if 'address already in use' in str(e).lower():
                if port_ipv4 == port_ipv6 and bind_ipv4 and bind_ipv6 == '::':
                    LOGGER.warning(f'‚ö†Ô∏è  IPv6 bind to [::]:{port_ipv6} failed (port in use by IPv4)')
                    LOGGER.warning(f'‚ö†Ô∏è  This is normal on dual-stack systems')
                else:
                    LOGGER.error(f'‚úó Failed to bind IPv6 to [{bind_ipv6}]:{port_ipv6}: {e}')
            else:
                LOGGER.error(f'‚úó Failed to bind IPv6 to [{bind_ipv6}]:{port_ipv6}: {e}')
    
    # Verify we have at least one listener
    if not transports:
        LOGGER.error('Failed to bind to any interface')
        sys.exit(1)
    
    # Setup signal handlers
    def handle_shutdown(signum):
        signame = signal.Signals(signum).name
        LOGGER.info(f"Received shutdown signal {signame}")
        # Cleanup all protocols
        for protocol in protocols:
            protocol.cleanup()
        loop.stop()
    
    loop.add_signal_handler(signal.SIGINT, lambda: handle_shutdown(signal.SIGINT))
    loop.add_signal_handler(signal.SIGTERM, lambda: handle_shutdown(signal.SIGTERM))
    
    # Run forever
    try:
        await asyncio.Event().wait()
    except asyncio.CancelledError:
        pass

def main():
    """Entry point"""
    load_config()
    setup_logging()
    
    LOGGER.info('üöÄ ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê')
    LOGGER.info('üöÄ HBLINK4 STARTING UP')
    LOGGER.info('üöÄ ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê')
    
    asyncio.run(async_main())
```

**Pros:**
- ‚úÖ Explicit error handling per endpoint
- ‚úÖ Clear control flow
- ‚úÖ Easy to understand
- ‚úÖ Detailed logging
- ‚úÖ Handles dual-stack port conflicts gracefully

**Cons:**
- ‚ùå Verbose (lots of boilerplate)
- ‚ùå Protocol/transport tracking requires lists
- ‚ùå Manual cleanup coordination

**Risk Assessment:** LOW  
**Maintainability:** Good (explicit is better than implicit)

---

### Solution 3B: Factory Pattern with Cleanup Context Manager

**Approach:** Use factory pattern and context manager for lifecycle

```python
from contextlib import asynccontextmanager
from typing import List, Tuple

@asynccontextmanager
async def create_udp_listeners(loop):
    """
    Context manager to create and cleanup UDP listeners.
    Yields (transports, protocols) tuple.
    """
    bind_ipv4 = CONFIG.get('global', {}).get('bind_ipv4', '0.0.0.0')
    bind_ipv6 = CONFIG.get('global', {}).get('bind_ipv6', '::')
    port_ipv4 = CONFIG.get('global', {}).get('port_ipv4', 62031)
    port_ipv6 = CONFIG.get('global', {}).get('port_ipv6', 62031)
    disable_ipv6 = CONFIG.get('global', {}).get('disable_ipv6', False)
    
    transports = []
    protocols = []
    
    try:
        # Create IPv4
        if bind_ipv4:
            try:
                protocol = HBProtocol()
                transport, _ = await loop.create_datagram_endpoint(
                    lambda: protocol,
                    local_addr=(bind_ipv4, port_ipv4)
                )
                transports.append(transport)
                protocols.append(protocol)
                LOGGER.info(f'‚úì Listening on {bind_ipv4}:{port_ipv4} (IPv4)')
            except Exception as e:
                LOGGER.error(f'‚úó IPv4 bind failed: {e}')
                if bind_ipv4 == '0.0.0.0':
                    raise
        
        # Create IPv6
        if bind_ipv6 and not disable_ipv6:
            try:
                protocol = HBProtocol()
                transport, _ = await loop.create_datagram_endpoint(
                    lambda: protocol,
                    local_addr=(bind_ipv6, port_ipv6)
                )
                transports.append(transport)
                protocols.append(protocol)
                LOGGER.info(f'‚úì Listening on [{bind_ipv6}]:{port_ipv6} (IPv6)')
            except OSError as e:
                if 'in use' in str(e).lower():
                    LOGGER.warning(f'‚ö†Ô∏è  IPv6 bind skipped (port conflict - normal on dual-stack)')
                else:
                    LOGGER.error(f'‚úó IPv6 bind failed: {e}')
        
        if not transports:
            raise RuntimeError('No listeners created')
        
        # Yield to caller
        yield transports, protocols
        
    finally:
        # Cleanup on exit
        LOGGER.info("Closing UDP listeners...")
        for protocol in protocols:
            protocol.cleanup()
        for transport in transports:
            transport.close()

async def async_main():
    """Main async entry point"""
    loop = asyncio.get_running_loop()
    
    async with create_udp_listeners(loop) as (transports, protocols):
        # Setup signal handlers
        def handle_shutdown(signum):
            LOGGER.info(f"Received {signal.Signals(signum).name}")
            loop.stop()
        
        loop.add_signal_handler(signal.SIGINT, lambda: handle_shutdown(signal.SIGINT))
        loop.add_signal_handler(signal.SIGTERM, lambda: handle_shutdown(signal.SIGTERM))
        
        # Run forever
        await asyncio.Event().wait()

def main():
    load_config()
    setup_logging()
    LOGGER.info('üöÄ HBlink4 starting up')
    
    try:
        asyncio.run(async_main())
    except KeyboardInterrupt:
        LOGGER.info("Shutdown complete")
```

**Pros:**
- ‚úÖ Context manager ensures cleanup
- ‚úÖ Separation of concerns (factory vs main loop)
- ‚úÖ Automatic cleanup on any exit path
- ‚úÖ Reusable pattern
- ‚úÖ Cleaner async_main() function

**Cons:**
- ‚ùå More abstraction (context manager)
- ‚ùå Less explicit control flow
- ‚ùå Cleanup happens outside signal handler (signal just stops loop)

**Risk Assessment:** LOW  
**Maintainability:** Excellent (separation of concerns)

---

### Solution 3C: Simplified Single-Protocol Dual-Stack

**Approach:** Use single protocol instance with smart addressing

```python
async def async_main():
    """Main async entry point"""
    loop = asyncio.get_running_loop()
    
    bind_ipv4 = CONFIG.get('global', {}).get('bind_ipv4', '0.0.0.0')
    bind_ipv6 = CONFIG.get('global', {}).get('bind_ipv6', '::')
    port = CONFIG.get('global', {}).get('port_ipv4', 62031)
    disable_ipv6 = CONFIG.get('global', {}).get('disable_ipv6', False)
    
    # Create single protocol instance
    protocol = HBProtocol()
    transport = None
    
    # Try IPv6 first (can handle IPv4 too on dual-stack systems)
    if bind_ipv6 and not disable_ipv6:
        try:
            transport, _ = await loop.create_datagram_endpoint(
                lambda: protocol,
                local_addr=(bind_ipv6, port)
            )
            LOGGER.info(f'‚úì HBlink4 listening on [::]:{port} (IPv6, dual-stack)')
        except Exception as e:
            LOGGER.warning(f'IPv6 bind failed: {e}, falling back to IPv4')
    
    # Fallback to IPv4 if IPv6 failed or disabled
    if transport is None and bind_ipv4:
        try:
            transport, _ = await loop.create_datagram_endpoint(
                lambda: protocol,
                local_addr=(bind_ipv4, port)
            )
            LOGGER.info(f'‚úì HBlink4 listening on {bind_ipv4}:{port} (IPv4 only)')
        except Exception as e:
            LOGGER.error(f'Failed to bind: {e}')
            sys.exit(1)
    
    if transport is None:
        LOGGER.error('No listeners created')
        sys.exit(1)
    
    # Signal handlers
    def handle_shutdown(signum):
        LOGGER.info(f"Received {signal.Signals(signum).name}")
        protocol.cleanup()
        loop.stop()
    
    loop.add_signal_handler(signal.SIGINT, lambda: handle_shutdown(signal.SIGINT))
    loop.add_signal_handler(signal.SIGTERM, lambda: handle_shutdown(signal.SIGTERM))
    
    await asyncio.Event().wait()

def main():
    load_config()
    setup_logging()
    LOGGER.info('üöÄ HBlink4 starting up')
    asyncio.run(async_main())
```

**Pros:**
- ‚úÖ Simplest code (fewest lines)
- ‚úÖ Single protocol instance (simpler state management)
- ‚úÖ Leverages dual-stack where available
- ‚úÖ Clear fallback chain (IPv6 ‚Üí IPv4)

**Cons:**
- ‚ùå Can't bind both IPv4 and IPv6 separately
- ‚ùå Different behavior from current implementation
- ‚ùå May not work on all network configs

**Risk Assessment:** MEDIUM (behavior change)  
**Maintainability:** Good (simple) but changes semantics

---

### Solution 3: FINAL RECOMMENDATION

**Selected:** **Solution 3A (Sequential Endpoint Creation)**

**Rationale:**
1. **Maintains current behavior:** Separate IPv4/IPv6 listeners like Twisted version
2. **Explicit error handling:** Clear logging for each bind attempt
3. **Backward compatible:** No semantic changes from v1.6.0
4. **Debuggable:** Easy to see what succeeded/failed
5. **Production tested:** Pattern matches current working implementation

**Why not 3B:**
- Context manager is elegant but adds abstraction without clear benefit
- Signal handler cleanup coordination is clearer in 3A
- Explicit > implicit for critical initialization code

**Why not 3C:**
- **Semantic change:** Current code explicitly creates separate listeners
- **Compatibility risk:** Some networks may require separate IPv4/IPv6 binds
- **Deployment risk:** Behavior change could break existing installations

**Confidence Level:** HIGH (3A is safest, maintains semantics)

---

## Migration Checkpoints Summary

### Checkpoint 1: Imports & Base Class ‚úÖ
- Change imports from twisted to asyncio
- Update HBProtocol base class
- **Risk:** None (purely syntactic)
- **Rollback:** Trivial (revert imports)

### Checkpoint 2: Method Renames ‚úÖ
- datagramReceived ‚Üí datagram_received
- startProtocol ‚Üí connection_made
- stopProtocol ‚Üí connection_lost
- **Risk:** None (method name changes only)
- **Rollback:** Trivial (revert method names)

### Checkpoint 3: Signal Handlers ‚ö†Ô∏è
- Implement Solution 1A (asyncio native)
- **Risk:** Low (well-tested pattern)
- **Rollback:** Revert to Twisted signal handling

### Checkpoint 4: Periodic Tasks ‚ö†Ô∏è
- Implement Solution 2B (generic helper)
- **Risk:** Low (isolated task timing)
- **Rollback:** Revert to LoopingCall

### Checkpoint 5: Event Loop Setup ‚ö†Ô∏è
- Implement Solution 3A (sequential endpoints)
- **Risk:** Low-Medium (main initialization)
- **Rollback:** Revert to reactor.run()

### Checkpoint 6: Integration Testing ‚ö†Ô∏è
- Test with real repeaters
- Monitor packet loss, latency
- **Risk:** Medium (full system test)
- **Rollback:** Merge v1.6.0 back to main

---

## Next Steps

1. ‚úÖ **Create v1.6.0 release tag** - DONE
2. ‚úÖ **Create feature/asyncio-migration branch** - DONE
3. ‚è≥ **Implement Checkpoint 1** - Imports & base class
4. ‚è≥ **Implement Checkpoint 2** - Method renames
5. ‚è≥ **Implement Checkpoint 3** - Signal handlers (Solution 1A)
6. ‚è≥ **Implement Checkpoint 4** - Periodic tasks (Solution 2B)
7. ‚è≥ **Implement Checkpoint 5** - Event loop (Solution 3A)
8. ‚è≥ **Test & validate** - Integration testing
9. ‚è≥ **Merge to main** - After validation

---

## Confidence Assessment

| Component | Confidence | Rationale |
|-----------|------------|-----------|
| Overall Migration | HIGH | Simple UDP architecture, no complex async interactions |
| Signal Handlers | HIGH | All 3 solutions viable, selected best for Unix |
| Periodic Tasks | HIGH | Generic helper is clearly superior, DRY principle |
| Event Loop Setup | HIGH | Sequential creation maintains semantics |
| Rollback Safety | HIGH | Git checkpoints at every step |
| Performance Impact | MEDIUM-HIGH | Expected improvement, requires measurement |

**Overall Risk:** LOW-MEDIUM  
**Expected Timeline:** 2-3 days (including testing)  
**Recommendation:** PROCEED with phased rollout
